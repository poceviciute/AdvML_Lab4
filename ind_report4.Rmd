---
title: '732A96 Lab 4: Gaussian Processes'
author: "Fanny Karelius (fanka300)"
date: "17 october 2018"
output:
  word_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(987654321)
library(readr)
library(kernlab)
library(AtmRay)
library(knitr)
```

# Question 2.1 Implementing GP Regression

##1
```{r, echo=FALSE}
#Confidence bands
conf_band <- function(mean, var){
  upp_band <- mean+qnorm(0.975)*sqrt(diag(var))
  low_band <- mean-qnorm(0.975)*sqrt(diag(var))
  return(list(upper=upp_band, lower=low_band))
}
```

The following Gaussian process regression model was implemented:

$$ y = f(x) + \epsilon, \ \ \epsilon \sim N(0, \sigma_n^2), \ \  f \sim GP(0, k(x,x^\prime))$$

The function posteriorGP has the inputs:

- x: Vector of training points
- y: Vector of training targets
- xStar: Vector of inputs where the posterior distribution is to be evaluated ($X_{\star}$)
- hyperParam: List of two hyper parameters, $\sigma_f$ and $\ell$
- sigmaNoise: Noise (standard deviation $\sigma_n$)

The kernel used was the squared exponential kernel given by:
$$k(x,x_*)=\sigma_f^2\exp\{-\frac{1}{2}\left(\frac{x-x_*}{\ell}\right)^2\}$$

The output of the posteriorGP function is the posterior mean of $f$ and the posterior variance of $f$.

```{r}
############### 2.1
#1
SE_kernel <- function(sigmaf, ell){
  val <- function(x1, x2){
    n1 <- length(x1)
    n2 <- length(x2)
    K <- matrix(NA,n1,n2)
    for (i in 1:n2){
      K[,i] <- sigmaf^2*exp(-0.5*( (x1-x2[i])/ell)^2 )
    }
    return(K)
  }
  class(val) <- "kernel"
  return(val)
}

posteriorGP <- function(x, y, xStar, hyperParam, sigmaNoise){
  #### Input:
  #x = train data
  #y = targets
  #xStar = test data
  #hyperParam = list(sigmaF, l)
  #sigmaNoise
  #K covariance for indata, call se_kernel
  y <- as.matrix(y)
  sigmaF <- hyperParam$sigmaF
  l <- hyperParam$l
  kernel <- SE_kernel(sigmaF, l)
  k <- kernel(x, x)
  L <- t(chol(k+sigmaNoise^2*diag(ncol(k))))
  kStar <- kernel(x, xStar)
  alpha <- solve(t(L))%*%(solve(L)%*%y)
  fStar <- t(kStar)%*%alpha #predictive mean
  v <- solve(L)%*%kStar
  V <- kernel(xStar, xStar)-t(v)%*%v #predictive variance
  #log_marg <- -0.5*t(y)%*%alpha-sum(L) - 0.5*length(x)*log(2*pi)
  #### Output:
  #posterior mean, posterior variance
  return(list("pred_mean"=fStar, "pred_var"=V))
}

```


##2

The hyper parameters used are $\sigma_f = 1$, $\ell = 0.3$. The posterior was updated with one observation $(x,y)=(0.4,0.719)$. $\sigma_n$ was assumed to be $\sigma_n=0.1$. 

```{r}
#2
noise <- 0.1
hyperParam <- list("sigmaF"=1, "l"=0.3)
xGrid <- seq(-1,1,length=50)

obs1 <- list(x=0.4, y=0.719)
post1<-posteriorGP(obs1$x, obs1$y, xGrid, hyperParam, noise)
confband1 <- conf_band(post1$pred_mean, post1$pred_var)

```

```{r, echo=FALSE}
plot(xGrid, post1$pred_mean, type="l", ylim=c(-2,4), ylab="Posterior mean", xlab = "x", main="One observation")
lines(xGrid,confband1$upper, col="blue")
lines(xGrid,confband1$lower, col="blue")
abline(v=0.4,col="red")
legend("topleft",c("posterior mean", "probability bands", "observation"),
       col = c("black","blue", "red"), lty = c(1, 1, 1), lwd=c(1, 1, 1))

```

The plot shows the posterior mean and the 95% point wise probability bands plotted over a grid $[-1,1]$.
The probability bands are very wide except for where the observation is because the uncertainty has decreased here.

##3

The posterior was updated with one more observation $(x,y)=(-0.6,-0.044)$. 

```{r}
#3
obs2 <- list(x=c(obs1$x,-0.6), y=c(obs1$y,-0.044))
post2 <- posteriorGP(obs2$x, obs2$y, xGrid, hyperParam, noise)
confband2 <- conf_band(post2$pred_mean, post2$pred_var)

```

```{r, echo=FALSE}
plot(xGrid, post2$pred_mean, type="l", ylim=c(-2,4), ylab="Posterior mean", xlab = "x", main="Two observations")
lines(xGrid,confband2$upper, col="blue")
lines(xGrid,confband2$lower, col="blue")
abline(v=0.4,col="red")
abline(v=-0.6,col="red")
legend("topright",c("posterior mean", "probability bands", "observations"),
       col = c("black","blue","red"), lty = c(1, 1, 1), lwd=c(1, 1, 1))

```

The plot shows the posterior mean and the 95% point wise probability bands plotted over a grid $[-1,1]$.
The probability bands are again very wide except for where the observations are because the uncertainty has decreased here.

##4

The plot below shows the posterior mean and the 95% probability bands after the posterior has been updated with 3 more observations. The uncertainty has decreased more compared to when we only had one and two observations (as indicated by the decreased width of the probability bands).

```{r, results="asis"}
#4
obs3 <- list(x=c(obs2$x, -1, -0.2, 0.8), y=c(obs2$y, 0.768, -0.94, -0.664))
kable(as.data.frame(obs3), caption = "Observations")
post3 <- posteriorGP(obs3$x, obs3$y, xGrid, hyperParam, noise)
confband3 <- conf_band(post3$pred_mean, post3$pred_var)

```

```{r, echo=FALSE}
plot(xGrid, post3$pred_mean, type="l", ylim=c(-2,2), ylab="Posterior mean", xlab = "x", main="Five observations")
lines(xGrid,confband3$upper, col="blue")
lines(xGrid,confband3$lower, col="blue")
legend("topright",c("posterior mean", "probability bands"),
       col = c("black","blue"), lty = c(1, 1), lwd=c(1, 1))

```


##5

The plot below shows the posterior mean and the 95% probability bands after 5 observations as in part 4, but here the hyper parameters were $\sigma_f = 1$, $\ell = 1$. 

```{r}
#5
hyperParam2 <- list(sigmaF=1, l=1)
post4 <- posteriorGP(obs3$x, obs3$y, xGrid, hyperParam2, noise)
confband4 <- conf_band(post4$pred_mean, post4$pred_var)

```

```{r, echo=FALSE}
plot(xGrid, post4$pred_mean, type="l", ylim=c(-1.5,1), ylab="Posterior mean", xlab = "x", main="sigmaF=1, l=1")
lines(xGrid,confband4$upper, col="blue")
lines(xGrid,confband4$lower, col="blue")
legend("topright",c("posterior mean", "probability bands"),
       col = c("black","blue"), lty = c(1, 1), lwd=c(1, 1))

```

As can be seen in the plot (when compared to the plot in part 4), the posterior mean becomes smoother with a higher $\ell$ value. This is because the distance between the points is divided by $\ell$ in the kernel and when $\ell$ becomes larger the exponential will go to 1 and the kernel value will go to $\sigma_f$. Thus, the distance between the points will have less influence on the kernel value and the posterior mean becomes smoother.

# Question 2.2 GP Regression with _kernlab_

For this exercise, data of daily mean temperatures in Tullinge are used.

##1


```{r}
################### 2.2
#1
TempTullinge <- read.csv("D:/LiU/732A96/AdvML_Lab4/TempTullinge.csv", header=TRUE, sep=";")

time <- 1:length(TempTullinge$date)
day <- 1:365
fTime <- seq(from=time[1], to=time[length(time)], by = 5)
fDay <- seq(from=day[1], to=day[length(day)], by = 5)
temp <- TempTullinge$temp[fTime]

kernel_func <- SE_kernel(sigmaf=1, ell=0.3)
point1 <- c(1,2)
kernel_point1 <- kernel_func(point1[1], point1[2])
x_vec <- c(1,3,4)
xStar_vec <- c(2,3,4)
k_cov1<-kernelMatrix(kernel = kernel_func, x = x_vec, y = xStar_vec)

```

For the point $x=1, x'=2$, the squared exponential kernel value (with $\sigma_f=1, \ell = 0.3$) was `r kernel_point1`.

For the vectors $X=(1,3,4)^T$ and $X_*=(2,3,4)^T$, the covariance matrix (with $\sigma_f=1, \ell = 0.3$) was 
```{r, echo=FALSE}
k_cov1

```


##2

The following model was used to obtain the posterior mean:
$$temp = f(time) + \epsilon, \ \ \epsilon \sim N(0,\sigma_n^2), \ \ f \sim GP(0,k(time,time^{'}))$$

$\sigma_n^2$ was obtained by taking the variance of the residuals from a quadratic regression of $temp$ as a function of $time$.

The hyper parameters used in the squared exponential kernel were $\sigma_f=20, \ell=0.2$. A Gaussian process model was fitted on every fifth observation. The posterior mean was calculated by predicting on the training data.

```{r}
#2
lm_fit <- lm(temp~time+time^2, data = TempTullinge)
sigma2n <- var(lm_fit$residuals)
kernel_func2 <- SE_kernel(sigmaf=20, ell=0.2)
gp_model <- gausspr(fTime,temp,data=TempTullinge, kernel=kernel_func2, var=sigma2n)
post_mean <- predict(gp_model, fTime)

```


```{r, echo=FALSE}
plot(fTime, temp, pch=20, main="Posterior mean of f", xlab="Time")
lines(fTime,post_mean, col="blue", lwd=2)
legend("bottomright",c("observations", "posterior mean (time)"),
       col = c("black","blue"), pch=c(20,-1), lty = c(0, 1), lwd=c(0, 1))

```

The plot shows the observations plotted with the fitted posterior mean. The posterior mean fits the data quite well. It predicts the trends of the data (the periodicity).

##3

```{r}
#3
x <- scale(fTime)
xs <- scale(fTime)
n <- length(fTime)
Kss <- kernelMatrix(kernel = kernel_func2, x = xs, y = xs)
Kxx <- kernelMatrix(kernel = kernel_func2, x = x, y = x)
Kxs <- kernelMatrix(kernel = kernel_func2, x = x, y = xs)
Covf = Kss-t(Kxs)%*%solve(Kxx + sigma2n*diag(n), Kxs) # Covariance matrix of fStar

```


```{r, echo=FALSE}
plot(fTime, temp, ylim=c(-40,35), pch=20, main="Posterior mean of f", xlab="Time")
lines(fTime,post_mean, col="blue", lwd=2)
# Probability intervals for fStar
lines(fTime, post_mean - 1.96*sqrt(diag(Covf)), col = "red", lwd=2)
lines(fTime, post_mean + 1.96*sqrt(diag(Covf)), col = "red", lwd=2)
# Prediction intervals for yStar
lines(fTime, post_mean - 1.96*sqrt((diag(Covf) + sigma2n)), col = "red", lwd=2, lty=2)
lines(fTime, post_mean + 1.96*sqrt((diag(Covf) + sigma2n)), col = "red", lwd=2, lty=2)
legend("bottomright",c("posterior mean (time)", "probability bands","prediction bands"),
       col = c("blue","red", "red"), lty = c(1, 1, 5), lwd=c(1, 1, 1))

```

The plot shows the observations, posterior mean, the probability and prediction bands. The probability and prediction bands fit the data well, but the prediction bands are very wide and enclose all observations.

##4

The following model was used to obtain the posterior mean:
$$temp = f(day) + \epsilon, \ \ \epsilon \sim N(0,\sigma_n^2), \ \ f \sim GP(0, k(day, day^\prime))$$

$\sigma_n^2$ was obtained by taking the variance of the residuals from a quadratic regression of $temp$ as a function of $day$.

The hyper parameters used in the squared exponential kernel were $\sigma_f=20, \ell=0.2$. A Gaussian process model was fitted on every fifth observation. The posterior mean was calculated by predicting on the training data.

```{r}
#4
fDay_rep <- rep(fDay,6)
lm_fit2 <- lm(temp~fDay_rep+fDay_rep^2)
sigma2n_day <- var(lm_fit2$residuals)
kernel_func3 <- SE_kernel(sigmaf=20, ell=1.2)
gp_model2 <- gausspr(fDay_rep,temp,data=TempTullinge, kernel=kernel_func3, var=sigma2n_day)
post_mean2 <- predict(gp_model2, fDay_rep)

```

```{r, echo=FALSE}
plot(fTime, temp, ylim=c(-25,25), pch=20, main="Posterior mean of f", xlab="Time")
lines(fTime,post_mean, col="blue", lwd=2)
lines(fTime,post_mean2, col="red", lwd=2)
legend("bottomright",c("posterior mean (time)","posterior mean (day)"),
       col = c("blue","red"), lty = c(1,1), lwd=c(1,1))

```

The model with prediction variable $time$ shows a more smooth posterior mean curve than the model with prediction variable $day$.
The posterior mean for $day$ captures the seasonal trend of the temperature (as the $day=1,2,...,365$ variable is replicated 6 times), but the posterior mean for $time$ captures the overall trend of temperature. 
It seems that it is better to use the model with $time$ as predictor to see the overall change of temperature whereas it is better to use the model with $day$ as predictor to see the how the temperature changes within a year.


##5

A GP with a generalization of the periodic kernel was used to model the temperature against time.

The periodic kernel is given by:
$$k(x,x')=\sigma_f^2\exp{\{-\frac{2\sin^2(pi|x-x'|)/d}{\ell_1^2}\}}\exp{\{-\frac{|x-x'|^2}{2\ell_2^2}\}}$$

The hyper parameters used in the kernel were $\sigma_f=20, \ell_1=1, \ell_2=10, d=365/\text{sd}(time)$.

```{r}
#5
periodic_kernel <- function(sigmaf, ell1, ell2, d){
  val <- function(x1, x2){
    n1 <- length(x1)
    n2 <- length(x2)
    K <- matrix(NA,n1,n2)
    for (i in 1:n2){
      K[,i] <- sigmaf^2*exp(-2*sin(pi*abs(x1-x2[i])/d)^2/ell1^2)*exp(-0.5*abs(x1-x2[i])^2/ell2^2)
    }
    return(K)
  }
  class(val) <- "kernel"
  return(val)  
}

periodic_k <- periodic_kernel(20, 1, 10, 365/sd(time))
gp_model3 <- gausspr(fTime,temp,data=TempTullinge, kernel=periodic_k, var=sigma2n_day)
post_mean3 <- predict(gp_model3, fTime)

```

```{r, echo=FALSE}
plot(fTime, temp, pch=20, main="Posterior mean of f", xlab="Time")
lines(fTime,post_mean, col="blue", lwd=2)
lines(fTime,post_mean2, col="red", lwd=2)
lines(fTime,post_mean3, col="green", lwd=2)
legend("bottomright",c("posterior mean (time)","posterior mean (day)","posterior mean (periodic)"),
       col = c("blue","red","green"), lty = c(1, 1, 1), lwd=c(1, 1, 1))

```

From the plot above, it seems that the periodic kernel model captures how the temperature changes within a year for each year instead of just one year as with the squared exponential kernel model with $day$ as predictor. The periodic kernel has one more lenght scale that controls how much the distance bewteen the same day in different years should influence the kernel value.

It also seems that the periodic kernel model captures the seasonality of the data more than the model with $time$ as predictor (and squared exponential kernel).

# Question 2.3 GP Classification with kernlab

Banknote fraud data was used to fit a Gaussian process classification model. 1000 observations were used as training data and the rest as test data.

##1

Using the `kernlab` library, a GP classification model was trained on the training data using the covariates $varWave$ and $skewWave$.

```{r, message=FALSE}
######################## 2.3
fraud_data <- read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/banknoteFraud.csv", header=FALSE, sep=",")
names(fraud_data) <- c("varWave","skewWave","kurtWave","entropyWave","fraud") 
fraud_data[,5] <- as.factor(fraud_data[,5])

#1
set.seed(111)
SelectTraining <- sample(1:dim(fraud_data)[1], size = 1000, replace = FALSE)
fraud_train <- fraud_data[SelectTraining,]
fraud_test <- fraud_data[-SelectTraining,]
gp_fraud1 <- gausspr(fraud~varWave+skewWave, data=fraud_train)
x1 <- seq(min(fraud_data$varWave),max(fraud_data$varWave),length=100)
x2 <- seq(min(fraud_data$skewWave),max(fraud_data$skewWave),length=100)
fraud_grid <- meshgrid(x1,x2)
grid_points <- data.frame(cbind(c(fraud_grid$x), c(fraud_grid$y)))
names(grid_points) <- c("varWave","skewWave")
probPreds1 <- predict(gp_fraud1, grid_points, type="probabilities")

```

The contours of prediction probability were plotted over a grid of $varWave$ and $skewWave$ values. The training data was overlayed.

```{r, echo=FALSE}
contour(x1,x2,matrix(probPreds1[,1], 100, byrow = TRUE), xlab = "varWave", ylab = "skewWave", main = 'Prob(fraud) - fraud is blue')
points(fraud_train[fraud_train$fraud==0,"varWave"],fraud_train[fraud_train$fraud==0,"skewWave"],col="red",pch=20)
points(fraud_train[fraud_train$fraud==1,"varWave"],fraud_train[fraud_train$fraud==1,"skewWave"],col="blue",pch=20)

conf_mat1<-table("Prediction"=predict(gp_fraud1, fraud_train[,1:2]), "True"=fraud_train$fraud)
accuracy1<-sum(diag(conf_mat1))/sum(conf_mat1)

```

The confusion matrix and accuracy rate are given by

```{r, echo=FALSE}
conf_mat1
accuracy1

```


##2

Using the model obtained, predictions were made on the test data. The confusion matrix and accuracy rate was

```{r}
#2
conf_mat2<-table("Prediction"=predict(gp_fraud1, fraud_test[,1:2]), "True"=fraud_test$fraud)
accuracy2<-sum(diag(conf_mat2))/sum(conf_mat2)
conf_mat2
accuracy2
```

The accuracy is `r accuracy2`, which is pretty close to the accuracy rate obtained on the training data. This is indications that the model is not over fitting the training data. The accuracy rate is also quite high in both cases so the model is working well.

##3

Using all four covariates, a GP classification model was trained on the training data and then predictions were made using the test data. 

```{r, results="hide"}
#3
gp_fraud2 <- gausspr(fraud~., data=fraud_train)
conf_mat3<-table("Prediction"=predict(gp_fraud2, fraud_test), "True"=fraud_test$fraud)
accuracy3<-sum(diag(conf_mat3))/sum(conf_mat3)

```

The confusion matrix and accuracy rate was
```{r, echo=FALSE}
conf_mat3
accuracy3
```

Here, the accuracy is very close to 1. The result with only two covariates was not bad since the accuracy was `r accuracy2`, but the result is better when all covariates are considered because we use all information available.

#Appendix

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```
